{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu up\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "    print(\"gpu up\")\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 150  # for Binarize\n",
    "\n",
    "\n",
    "def Binarize(X):\n",
    "    X[X < threshold] = 0\n",
    "    X[X >= threshold] = 1\n",
    "    return X\n",
    "\n",
    "\n",
    "# train_X = Binarize(train_X)\n",
    "# test_X = Binarize(test_X)\n",
    "\n",
    "def Normalize(X):\n",
    "    return X/255\n",
    "\n",
    "# train_X = Normalize(train_X)\n",
    "# test_X = Normalize(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(arr):\n",
    "    moments = {'M00': arr.sum(axis=1).sum(),\n",
    "               'M01': (np.arange(start=1, stop=arr.shape[1] + 1, step=1) * arr.sum(axis=0).reshape(1, -1)).sum(),\n",
    "               'M10': (np.arange(start=1, stop=arr.shape[0] + 1, step=1) * arr.sum(axis=1).reshape(1, -1)).sum(),\n",
    "               'M11': 0}\n",
    "\n",
    "    x = moments['M10'] / moments['M00'] if moments['M00'] != 0 else 0\n",
    "    y = moments['M01'] / moments['M00'] if moments['M00'] != 0 else 0\n",
    "    return [x, y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageWin(trainx, r, c):\n",
    "    temp = []\n",
    "    for i in range(0, int(trainx.shape[0]), r):\n",
    "        for j in range(0, int(trainx.shape[1]), c):\n",
    "            temp.append(centroid(trainx[i:i+r, j:j+c]))\n",
    "    return np.array(temp)\n",
    "\n",
    "\n",
    "def slicingArray(trainX, r, c):\n",
    "    featureVector = []\n",
    "    for trainx in trainX:\n",
    "        featureVector.append(imageWin(trainx, r, c))\n",
    "    return np.array(featureVector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffling the dataset\n",
    "\n",
    "train_X, train_y = shuffle(train_X[:15000], train_y[:15000])\n",
    "test_X, test_y = shuffle(test_X[:1000], test_y[:1000])\n",
    "\n",
    "train_y =  (np.eye(10)[np.array(train_y)]).tolist()\n",
    "test_y = (np.eye(10)[np.array(test_y)]).tolist()\n",
    "\n",
    "arr = slicingArray(train_X, 4, 7)\n",
    "# trainFeatureVec = arr.reshape([*arr.shape[:-2], -1])\n",
    "\n",
    "trainFeatureVec = arr.tolist()\n",
    "\n",
    "# print(trainFeatureVec.shape)\n",
    "\n",
    "arr = slicingArray(test_X, 4, 7)\n",
    "# testFeatureVec = arr.reshape(*arr.shape[:-2], -1)\n",
    "testFeatureVec = arr.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Fundamental Functions\n",
    "def listXlist(l1: list, l2:list):\n",
    "    res = [[0 for i in range(len(l2[0]))] for j in range(len(l1))]\n",
    "    for i in range(len(l1)):\n",
    "        for j in range(len(l2[0])):\n",
    "            for k in range(len(l2)):\n",
    "                res[i][j] += l1[i][k] * l2[k][j]\n",
    "    return res\n",
    "\n",
    "def listMINUSlist(l1: list, l2:list):\n",
    "    res = [[0 for i in range(len(l2[0]))] for j in range(len(l2))]\n",
    "    for i in range(len(l2)):\n",
    "        for j in range(len(l1[0])):\n",
    "                res[i][j] = l1[i][j] - l2[i][j]\n",
    "    return res\n",
    "\n",
    "def listSquare(l: list):\n",
    "    res = []\n",
    "    for i in range(len(l)):\n",
    "        res.append([l[i]**2])\n",
    "    return res\n",
    "\n",
    "def mean(k: list):\n",
    "    return sum([i[0] for i in k]) / len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_11192/2000784436.py, line 75)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\miret\\AppData\\Local\\Temp/ipykernel_11192/2000784436.py\"\u001b[1;36m, line \u001b[1;32m75\u001b[0m\n\u001b[1;33m    self.weights[self.layers][i][j] -= self.learning_rate * dw self.__derivatives(self.neuronsListBefore[self.layers][i][0], self.activationFn) * self\u001b[0m\n\u001b[1;37m                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Fully connected NN\n",
    "class NN:\n",
    "    def __init__(self, m: int, n: list, activation: str, e: int, lr: float, outShape: int):\n",
    "        self.neurons = n\n",
    "        self.neuronsListBefore = []\n",
    "        self.neuronsListAfter = []\n",
    "        self.layers = m\n",
    "        self.weights = dict([(x, [0]) for x in range(self.layers + 1)])\n",
    "        self.grads = dict([(x, [0]) for x in range(self.layers + 1)])\n",
    "        # self.bias = np.random.random()\n",
    "        self.activationFn = activation\n",
    "        self.learning_rate = lr\n",
    "        self.epochs = e\n",
    "        self.outputShape = outShape\n",
    "\n",
    "    # MSE\n",
    "    def __costFunc(self, y, preds):\n",
    "        return 0.5 * listSquare(listMINUSlist(y, preds))\n",
    "\n",
    "    def __activation(self, x: float, type: str):\n",
    "        res = {\n",
    "            'sigmoid': 1 / (1 + math.exp(-x)),\n",
    "            'tanh': math.tanh(x),\n",
    "            'relu': max(x, 0),\n",
    "            'leaky_relu': max(0.1 * x, x),\n",
    "        }\n",
    "        return res[type]\n",
    "\n",
    "    def __derivatives(self, out: float, type: str):\n",
    "        res = {\n",
    "            'sigmoid': out * (1 - out),\n",
    "            'tanh': 1 - (out ** 2),\n",
    "            'relu': 0 if out < 0 else 1,\n",
    "            'leaky_relu': 0.1 if out < 0 else 1,\n",
    "        }\n",
    "        return res[type]\n",
    "\n",
    "    def __initializeWeights(self, input: list, outputShape: int):\n",
    "        self.weights[0] = [[random.random() for i in range(len(input))] for j in range(self.neurons[0])]\n",
    "        self.grads[0] = [[0 for i in range(len(input))] for j in range(self.neurons[0])]\n",
    "\n",
    "        for i in range(1, self.layers):\n",
    "            self.weights[i] = [[random.random() for i in range(self.neurons[i - 1])] for j in range(self.neurons[i])]\n",
    "            self.grads[i] = [[0 for i in range(len(input))] for j in range(self.neurons[0])]\n",
    "\n",
    "        self.weights[self.layers] = [[random.random() for i in range(outputShape)] for j in range(self.neurons[self.layers - 1])]\n",
    "        self.grads[self.layers] = [[0 for i in range(len(input))] for j in range(self.neurons[0])]\n",
    "\n",
    "\n",
    "    def fit(self, trainX: list, trainY: np.array):\n",
    "        self.__initializeWeights(trainX, self.outputShape)\n",
    "        self.neuronsListAfter.append(trainX)\n",
    "        for epoch in range(self.epochs):\n",
    "            outputLayer = self.__propagate(trainX)\n",
    "            self.__backPropagation(trainY, outputLayer)\n",
    "            self.updateWeights()\n",
    "\n",
    "\n",
    "    def __feedForward(self, input: list, layerIdx: int) -> list:\n",
    "        out = []\n",
    "        x = []\n",
    "        x = listXlist(self.weights[layerIdx], input)\n",
    "        self.neuronsListBefore.append(x)\n",
    "        for i in range(len(x)):\n",
    "            out.append([self.__activation(x[i][0], self.activationFn)])\n",
    "\n",
    "        self.neuronsListAfter.append(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __propagate(self, x: list):\n",
    "        out = self.__feedForward(x, 0)\n",
    "        for i in range(1, self.layers + 1):\n",
    "            out = self.__feedForward(out, i)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __backPropagation(self, target: list, outputLayer: list):\n",
    "        dw = -1 * mean(listMINUSlist(target, outputLayer))\n",
    "        deltas = dict([(x, [0]) for x in range(self.layers + 1)])\n",
    "        for i in range(len(self.weights[self.layers])):\n",
    "            deltas[self.layers][i] = np.array(listMINUSlist(target, outputLayer))/-10\n",
    "            for j in range(len(self.weights[self.layers][0])):\n",
    "                self.grads[self.layers][i][j] = deltas[self.layers][i] * self.neuronsListAfter[layer - 1][i][0] * self.__derivatives(self.neuronsListBefore[layer][i][0], self.activationFn)\n",
    "\n",
    "        [sum([self.weights[j][i] * delta[layer + 1][j] for j in range(len(delta[layer]))]) for i in range(len(weights))]\n",
    "\n",
    "        for layer in range(self.layers - 1, 1, -1):\n",
    "            delta[layer] = [sum([self.weights[layer + 1][j][i] * delta[layer + 1][j] for j in range(len(delta[layer]))]) * self.__derivatives(self.neuronsListBefore[layer][i][0], self.activationFn) for i in range(len(self.weights[layer + 1][0]))]\n",
    "            for i in range(len(self.weights[self.layers])):\n",
    "                for j in range(len(self.weights[self.layers][0])):\n",
    "                    self.grads[layer][i][j] = deltas[layer][i] * self.neuronsListAfter[layer - 1][i][0]\n",
    "\n",
    "\n",
    "    def updateWeights(self):\n",
    "        for layer in range(self.layers + 1):\n",
    "            for i in range(len(self.weights[self.layers])):\n",
    "                for j in range(len(self.weights[self.layers][0])):\n",
    "                    self.weights[layer][i][j] -= (self.grads[layer][i][j] * self.learning_rate)\n",
    "\n",
    "\n",
    "    def predict(self, testX: list):\n",
    "        preds = []\n",
    "        for i in range(len(testX)):\n",
    "            preds.append(self.__propagate(testX[i]))\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NN(2, [4, 4],'sigmoid', 1000, 0.03, 10)\n",
    "nn.fit([2,3,4], [1,0,1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0c17eaa54ce5f8c6735a61315d31bbb77188ab5bfff05492109242fb282d478"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('Tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
