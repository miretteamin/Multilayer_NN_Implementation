{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu up\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "  print(\"gpu up\")\n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "device = torch.device(dev)\n",
    "\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "\n",
    "def centroid(arr):\n",
    "    moments = {'M00': arr.sum(axis=1).sum(),\n",
    "               'M01': (np.arange(start=1, stop=arr.shape[1] + 1, step=1) * arr.sum(axis=0).reshape(1, -1)).sum(),\n",
    "               'M10': (np.arange(start=1, stop=arr.shape[0] + 1, step=1) * arr.sum(axis=1).reshape(1, -1)).sum(),\n",
    "               'M11': 0}\n",
    "\n",
    "    x = moments['M10'] / moments['M00'] if moments['M00'] != 0 else 0\n",
    "    y = moments['M01'] / moments['M00'] if moments['M00'] != 0 else 0\n",
    "    return [x, y]\n",
    "\n",
    "threshold = 150  # for Binarize\n",
    "\n",
    "\n",
    "def Binarize(X):\n",
    "    X[X < threshold] = 0\n",
    "    X[X >= threshold] = 1\n",
    "    return X\n",
    "\n",
    "\n",
    "train_X = Binarize(train_X)\n",
    "test_X = Binarize(test_X)\n",
    "\n",
    "\n",
    "def normalize(X):\n",
    "    mx = np.max(X)\n",
    "    return X/mx\n",
    "\n",
    "\n",
    "def imageWin(trainx, r, c):\n",
    "    temp = []\n",
    "    for i in range(0, int(trainx.shape[0]), r):\n",
    "        for j in range(0, int(trainx.shape[1]), c):\n",
    "            temp.append(centroid(trainx[i:i+r, j:j+c]))\n",
    "    return np.array(temp)\n",
    "\n",
    "\n",
    "def slicingArray(trainX, r, c):\n",
    "    featureVector = []\n",
    "    for trainx in trainX:\n",
    "        featureVector.append(imageWin(trainx, r, c))\n",
    "    return np.array(featureVector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Fundamental Functions\n",
    "def listXlist(l1: list, l2: list):\n",
    "    res = [[0 for i in range(len(l2[0]))] for j in range(len(l1))]\n",
    "    # print(len(l1),len(l1[0]),\" \",len(l2),len(l2[0]))\n",
    "    for i in range(len(l1)):\n",
    "        for j in range(len(l2[0])):\n",
    "            for k in range(len(l2)):\n",
    "                print(res[i][j])\n",
    "                res[i][j] += l1[i][k] * l2[k][j]\n",
    "    return res\n",
    "\n",
    "\n",
    "def listMINUSlist(l1: list, l2: list):\n",
    "    res = [[0 for i in range(len(l2[0]))] for j in range(len(l2))]\n",
    "    for i in range(len(l2)):\n",
    "        for j in range(len(l1[0])):\n",
    "            res[i][j] = l1[i][j] - l2[i][j]\n",
    "    return res\n",
    "\n",
    "\n",
    "def listSquare(l: list):\n",
    "    res = []\n",
    "    for i in range(len(l)):\n",
    "        res.append([l[i]**2])\n",
    "    return res\n",
    "\n",
    "\n",
    "def mean(k: list):\n",
    "    return sum([i[0] for i in k]) / len(k)\n",
    "\n",
    "\n",
    "def get_label(vector: list):\n",
    "    mx = 0\n",
    "    idx = 0\n",
    "    for i in range(len(vector)):\n",
    "        if(vector[i] > mx):\n",
    "            mx = vector[i]\n",
    "            idx = i\n",
    "    return idx\n",
    "\n",
    "\n",
    "def normalizeOut(vector: list):\n",
    "    mx = vector[get_label(vector)]\n",
    "    vector = [vector[i]/mx for i in range(len(vector))]\n",
    "    return vector\n",
    "\n",
    "\n",
    "def accuracy(target: list, predictions: list):\n",
    "    trueValues = [get_label(target[i]) for i in range(len(target))]\n",
    "    preds = [get_label(predictions[i]) for i in range(len(predictions))]\n",
    "    cnt = 0\n",
    "    for i in range(len(trueValues)):\n",
    "        if trueValues[i] == preds[i]:\n",
    "            cnt += 1\n",
    "\n",
    "    return cnt / float(len(trueValues)) * 100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the dataset\n",
    "\n",
    "# train_X, train_y = shuffle(train_X[:1500], train_y[:1500])\n",
    "# test_X, test_y = shuffle(test_X[:100], test_y[:100])\n",
    "\n",
    "train_X, train_y = train_X[:500], train_y[:500]\n",
    "test_X, test_y = test_X[:100], test_y[:100]\n",
    "\n",
    "arr = slicingArray(train_X, 4, 7)\n",
    "trainFeatureVec = normalize(arr)\n",
    "trainFeatureVec = trainFeatureVec.reshape([*arr.shape[:-2], -1])\n",
    "trainFeatureVec = np.expand_dims(trainFeatureVec, axis=-1)\n",
    "\n",
    "\n",
    "# print(trainFeatureVec.shape)\n",
    "\n",
    "trainFeatureVec = trainFeatureVec.tolist()\n",
    "\n",
    "\n",
    "arr = slicingArray(test_X, 4, 7)\n",
    "testFeatureVec = normalize(arr)\n",
    "testFeatureVec = testFeatureVec.reshape(*arr.shape[:-2], -1)\n",
    "testFeatureVec = np.expand_dims(testFeatureVec, axis=-1)\n",
    "\n",
    "\n",
    "train_y = (np.eye(10)[np.array(train_y)])\n",
    "test_y = (np.eye(10)[np.array(test_y)])\n",
    "train_y = np.expand_dims(train_y, axis=-1).tolist()\n",
    "test_y = np.expand_dims(test_y, axis=-1).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Fundamental Functions\n",
    "def listXlist(l1: list, l2: list):\n",
    "    res = [[0 for i in range(len(l2[0]))] for j in range(len(l1))]\n",
    "    # print(len(l1),len(l1[0]),\" \",len(l2),len(l2[0]))\n",
    "    for i in range(len(l1)):\n",
    "        for j in range(len(l2[0])):\n",
    "            for k in range(len(l2)):\n",
    "                res[i][j] += l1[i][k] * l2[k][j]\n",
    "    return res\n",
    "\n",
    "\n",
    "def listMINUSlist(l1: list, l2: list):\n",
    "    res = [[0 for i in range(len(l2[0]))] for j in range(len(l2))]\n",
    "    for i in range(len(l2)):\n",
    "        for j in range(len(l1[0])):\n",
    "            res[i][j] = l1[i][j] - l2[i][j]\n",
    "    return res\n",
    "\n",
    "\n",
    "def listSquare(l: list):\n",
    "    res = []\n",
    "    for i in range(len(l)):\n",
    "        res.append([l[i]**2])\n",
    "    return res\n",
    "\n",
    "\n",
    "def mean(k: list):\n",
    "    return sum([i[0] for i in k]) / len(k)\n",
    "\n",
    "\n",
    "def get_label(vector: list):\n",
    "    mx = 0\n",
    "    idx = 0\n",
    "    for i in range(len(vector)):\n",
    "        if(vector[i] > mx):\n",
    "            mx = vector[i]\n",
    "            idx = i\n",
    "    return idx\n",
    "\n",
    "\n",
    "def normalizeOut(vector: list):\n",
    "    mx = vector[get_label(vector)]\n",
    "    vector = [vector[i]/mx for i in range(len(vector))]\n",
    "    return vector\n",
    "\n",
    "\n",
    "def accuracy(target: list, predictions: list):\n",
    "    trueValues = [get_label(target[i]) for i in range(len(target))]\n",
    "    preds = [get_label(predictions[i]) for i in range(len(predictions))]\n",
    "    cnt = 0\n",
    "    for i in range(len(trueValues)):\n",
    "        if trueValues[i] == preds[i]:\n",
    "            cnt += 1\n",
    "\n",
    "    return cnt / float(len(trueValues)) * 100.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected NN\n",
    "class NN:\n",
    "    def __init__(self, m: int, n: list, activation: str, e: int, lr: float, outShape: int):\n",
    "        self.neurons = n                                                    # Neurons List to specify number of neurons in each layer\n",
    "        self.neuronsListBefore = []                                         # Net values\n",
    "        self.neuronsListAfter = []                                          # Neurons output values\n",
    "        self.layers = m                                                     # Number of layers\n",
    "        self.weights = dict([(x, [0]) for x in range(self.layers + 1)])     # Dictionary to save weights of each layer\n",
    "        self.bias = dict([(x, [0]) for x in range(self.layers + 1)])        # Dictionary to save bias of each layer\n",
    "        self.gradsWeights = []                                              # Dictionary to save weights gradients of each layer\n",
    "        self.gradsBias = []                                                 # Dictionary to save bias gradients of each layer\n",
    "        self.activationFn = activation                                      # String to specify layers' activation function\n",
    "        self.learning_rate = lr                                         \n",
    "        self.epochs = e\n",
    "        self.outputShape = outShape                                         # Number of neurons in output layer\n",
    "\n",
    "    # MSE\n",
    "    def __costFunc(self, y, preds):\n",
    "        return 0.5 * listSquare(listMINUSlist(y, preds)) /len(y)\n",
    "\n",
    "    def __activation(self, x: float, act: str):\n",
    "        # if act == 'sigmoid':\n",
    "        #     if x > 20:\n",
    "        #         return 0.00000001\n",
    "        #     elif x < -20:\n",
    "        #         return 0.99999999\n",
    "       \n",
    "        if act == \"sigmoid\":\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        if act == \"tanh\":\n",
    "            return np.tanh(x)\n",
    "\n",
    "        if act == \"linear\":\n",
    "            return x\n",
    "        if act==\"relu\":\n",
    "            return np.maximum(x, 0),\n",
    "        if act==\"leaky_relu\":\n",
    "            return np.maximum(0.1 * x, x)\n",
    "        \n",
    "        # return res[act]\n",
    "\n",
    "    def __derivatives(self, out: float, act: str):\n",
    "        if act == \"sigmoid\":\n",
    "            return out * (1-out)\n",
    "        if act==\"tanh\":\n",
    "            # print(out)\n",
    "            return 1 - (out ** 2)\n",
    "\n",
    "        if act==\"linear\":\n",
    "            return np.ones(out.shape)\n",
    "        if act==\"relu\":\n",
    "            re = np.ones(out.shape)\n",
    "            re[out<0] = np.zeros((out<0).shape)\n",
    "            return re\n",
    "        if act==\"leaky_relu\":\n",
    "            re = np.ones(out.shape)\n",
    "            re[out<0] = out[out<0] * 0.1\n",
    "            return re\n",
    "        \n",
    "\n",
    "    def __initializeWeightsBias(self, input: list):\n",
    "        self.weights[0] = np.array([[random.random() for i in range(len(input))]\n",
    "                           for j in range(self.neurons[0])],dtype=np.double)\n",
    "        self.bias[0] = np.array([[random.random()]\n",
    "                        for i in range(self.neurons[0])],dtype=np.double)\n",
    "\n",
    "        for i in range(1, self.layers):\n",
    "            self.weights[i] = np.array([[random.random() for i in range(\n",
    "                self.neurons[i - 1])] for j in range(self.neurons[i])],dtype=np.double)\n",
    "            self.bias[i] = np.array([[random.random()]\n",
    "                            for i in range(self.neurons[i])],dtype=np.double)\n",
    "\n",
    "        self.weights[self.layers] = np.array([[random.random() for i in range(\n",
    "            self.neurons[self.layers - 1])] for j in range(self.outputShape)],dtype=np.double)\n",
    "        self.bias[self.layers] = np.array([[random.random()]\n",
    "                                  for i in range(self.outputShape)],dtype=np.double)\n",
    "\n",
    "    def __zero_grads(self, input: list):\n",
    "        self.gradsWeights = dict([(x, [0]) for x in range(self.layers + 1)])\n",
    "        self.gradsBias = dict([(x, [0]) for x in range(self.layers + 1)])\n",
    "        self.gradsWeights[0] = np.array([[0 for i in range(len(input))]\n",
    "                                for j in range(self.neurons[0])],dtype=np.double)\n",
    "        self.gradsBias[0] = np.array([[0] for i in range(self.neurons[0])],dtype=np.double)\n",
    "\n",
    "        for i in range(1, self.layers):\n",
    "            self.gradsWeights[i] = np.array([\n",
    "                [0 for _ in range(self.neurons[i - 1])] for j in range(self.neurons[i])],dtype=np.double)\n",
    "            self.gradsBias[i] = np.array([[0] for i in range(self.neurons[i])],dtype=np.double)\n",
    "\n",
    "        self.gradsWeights[self.layers] = np.array([[0 for i in range(\n",
    "            self.neurons[self.layers - 1])] for j in range(self.outputShape)],dtype=np.double)\n",
    "        self.gradsBias[self.layers] = np.array([[0] for i in range(self.outputShape)],dtype=np.double)\n",
    "\n",
    "    def __feedForward(self, input: list, layerIdx: int) -> list:\n",
    "        out = []\n",
    "        x = []\n",
    "        # print(input,self.weights[layerIdx])\n",
    "        # print(layerIdx)\n",
    "        # print(input.shape)\n",
    "        # print(input)\n",
    "        x = (self.weights[layerIdx]@ input) + self.bias[layerIdx]\n",
    "        # x = [[x[i][0] + self.bias[layerIdx][i]] for i in range(len(x))]\n",
    "        # x = \n",
    "        self.neuronsListBefore.append(x)\n",
    "        # for i in range(len(x)):\n",
    "        #     out.append([self.__activation(x[i][0], self.activationFn)])\n",
    "        out = self.__activation(x, self.activationFn)\n",
    "        # print(out, \"<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "        self.neuronsListAfter.append(out)\n",
    "        return out\n",
    "\n",
    "    def __propagate(self, x: list):\n",
    "        self.neuronsListAfter.append(x)\n",
    "        out = self.__feedForward(x, 0)\n",
    "        for i in range(1, self.layers + 1):\n",
    "            out = self.__feedForward(out, i)\n",
    "        return out\n",
    "\n",
    "    def __backPropagation(self, target: list, outputLayer: list):\n",
    "        # print(len(outputLayer),outputLayer)\n",
    "        # dw = -1 * mean(listMINUSlist(target, outputLayer))\n",
    "        deltas = dict([(x, [0]) for x in range(self.layers + 1)])\n",
    "        # deltas[self.layers] = np.array(\n",
    "        #     [k[0] for k in listMINUSlist(target, outputLayer)])/-10\n",
    "        deltas[self.layers] = ( -1* (target-outputLayer)/10 )* (self.__derivatives(\n",
    "                self.neuronsListBefore[self.layers], self.activationFn))\n",
    "        self.gradsBias[self.layers]= deltas[self.layers]\n",
    "\n",
    "        # (neurons , 1) @ (1,neuronsBefore)   -> (neurons, neuronsBefore)\n",
    "        # self.gradsWeights[self.layers][i][j] = deltas[self.layers][i] * \\\n",
    "        #             self.neuronsListAfter[self.layers][j][0]\n",
    "        self.gradsWeights[self.layers] = deltas[self.layers] @ self.neuronsListAfter[self.layers].T\n",
    "       \n",
    "               \n",
    "\n",
    "        # [sum([self.weights[j][i] * delta[layer + 1][j] for j in range(len(delta[layer]))]) for i in range(len(weights))]\n",
    "\n",
    "        for layer in reversed(range(0, self.layers)):\n",
    "\n",
    "            # (neuron, 1) (neuron, neuronsBefore ) -> (neurons,Before)\n",
    "            deltas[layer] = (self.weights[layer + 1].T @ deltas[layer+1] )* self.__derivatives(\n",
    "                    self.neuronsListBefore[layer], self.activationFn)\n",
    "            self.gradsBias[layer] = deltas[layer]\n",
    "            self.gradsWeights[layer] = deltas[layer] @ self.neuronsListAfter[layer].T\n",
    "            \n",
    "            # deltas[layer] = [sum([self.weights[layer + 1][j][i] * deltas[layer + 1][j]\n",
    "            # #                      for j in range(len(deltas[layer]))]) for i in range(len(self.weights[layer + 1][0]))]\n",
    "            # for i in range(len(self.weights[layer])):\n",
    "            #     # deltas[layer][i] *= self.__derivatives(\n",
    "            #     #     self.neuronsListBefore[layer][i][0], self.activationFn)\n",
    "            #     # # print(deltas)\n",
    "            #     for j in range(len(self.weights[layer][0])):\n",
    "            #         # print(layer, i,j)\n",
    "            #         self.gradsWeights[layer][i][j] = deltas[layer][i] * \\\n",
    "            #             self.neuronsListAfter[layer][j][0]\n",
    "\n",
    "    def __updateWeightsBias(self):\n",
    "\n",
    "        for layer in range(self.layers + 1):\n",
    "            self.bias[layer] -= self.learning_rate * self.gradsBias[layer]\n",
    "            self.weights[layer] -= self.learning_rate * self.gradsWeights[layer] \n",
    "            self.weights[layer] -= self.learning_rate * self.weights[layer] *0.1\n",
    "            # for i in range(len(self.weights[layer])):\n",
    "            #     self.bias[layer][i] -= (self.learning_rate *\n",
    "            #                             self.gradsBias[layer][i])\n",
    "            #     for j in range(len(self.weights[layer][0])):\n",
    "            #         self.weights[layer][i][j] -= (self.gradsWeights[layer]\n",
    "            #                                       [i][j] * self.learning_rate)\n",
    "\n",
    "    def fit(self, trainX: list, trainY: list):\n",
    "        self.__initializeWeightsBias(trainX[0])\n",
    "        self.__zero_grads(trainX[0])\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(len(trainX)):\n",
    "                self.neuronsListBefore = []\n",
    "                self.neuronsListAfter = []\n",
    "                outputLayer = self.__propagate(trainX[i])\n",
    "                self.__backPropagation(trainY[i], outputLayer)\n",
    "                self.__updateWeightsBias()\n",
    "                self.__zero_grads(trainX[i])\n",
    "\n",
    "    def predict(self, testX: list):\n",
    "        preds = []\n",
    "        for i in range(len(testX)):\n",
    "            preds.append(self.__propagate(testX[i]))\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\traitlets-5.0.5.dist-info\\\\COPYING.md'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in c:\\programdata\\anaconda3\\lib\\site-packages (5.3.4)\n",
      "Collecting ipykernel\n",
      "  Downloading ipykernel-6.11.0-py3-none-any.whl (130 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel) (1.5.1)\n",
      "Collecting setuptools>=60\n",
      "  Downloading setuptools-61.3.1-py3-none-any.whl (1.1 MB)\n",
      "Collecting matplotlib-inline>=0.1\n",
      "  Downloading matplotlib_inline-0.1.3-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel) (5.8.0)\n",
      "Collecting ipython>=7.23.1\n",
      "  Downloading ipython-8.2.0-py3-none-any.whl (750 kB)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel) (6.1.12)\n",
      "Collecting debugpy>=1.0\n",
      "  Downloading debugpy-1.6.0-cp38-cp38-win_amd64.whl (4.3 MB)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel) (6.1)\n",
      "Collecting traitlets>=5.1.0\n",
      "  Downloading traitlets-5.1.1-py3-none-any.whl (102 kB)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.4)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.8.1)\n",
      "Collecting stack-data\n",
      "  Downloading stack_data-0.2.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.17.2)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.17)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (4.7.1)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (20.0.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel) (227)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel) (1.15.0)\n",
      "Collecting pure-eval\n",
      "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting executing\n",
      "  Downloading executing-0.8.3-py2.py3-none-any.whl (16 kB)\n",
      "Collecting asttokens\n",
      "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
      "Installing collected packages: traitlets, pure-eval, executing, asttokens, stack-data, setuptools, matplotlib-inline, ipython, debugpy, ipykernel\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.0.5\n",
      "    Uninstalling traitlets-5.0.5:\n"
     ]
    }
   ],
   "source": [
    "%pip install -U ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-f6b1cdf7e204>:125: RuntimeWarning: overflow encountered in multiply\n",
      "  deltas[self.layers] = ( -1* (target-outputLayer)/10 )* (self.__derivatives(\n",
      "<ipython-input-73-f6b1cdf7e204>:144: RuntimeWarning: invalid value encountered in matmul\n",
      "  self.gradsWeights[layer] = deltas[layer] @ self.neuronsListAfter[layer].T\n",
      "<ipython-input-73-f6b1cdf7e204>:162: RuntimeWarning: invalid value encountered in subtract\n",
      "  self.weights[layer] -= self.learning_rate * self.weights[layer]\n"
     ]
    }
   ],
   "source": [
    "nn = NN(2, [56,16], 'sigmoid', 5, 0.003, 10)\n",
    "nn.fit(np.array(trainFeatureVec,dtype=np.float64), train_y)\n",
    "\n",
    "testpreds = nn.predict(np.array(trainFeatureVec,dtype=np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpreds = nn.predict(np.array(testFeatureVec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-dc16f721f89d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-65-dc16f721f89d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sum([np.array(testpreds[i]).reshape(-1).argmax() ==np.array(train_y[i]).reshape(-1).argmax() for i in range(500)])/500"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
